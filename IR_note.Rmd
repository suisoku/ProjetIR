---
title: "Analyse des débats de l’assemblé national"
author: "ZIANI,MASSELIN,DIALLO,ANZID"
date: "09 mai 2019"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

##*Initiation à la Recherche*

Encadré par :
LABBE Cyril

Réalisé par :
DIALLO Thierno
MASSELIN Thibaut
ZIANI Nour-eddine
ANZID Samya

Année universitaire 2018/2019


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
#Package
install.packages("syuzhet")
install.packages("tm")
install.packages("tidyr")
```

# Résumé
Présentation d'une analyse réalisée sur un débat de l'Assemblée nationale. On traite les données brutes récupérer sur le site officiel des allocutions des participants. Ce type de donnée se prête bien à l’analyse textuelle, pour mettre en évidence certains sentiments en les classifications par famille. La méthode offre la possibilité de qualifier l’état d’esprit d’un texte.


# Introduction
Notre sujet porte sur les documents de l’Assemblée nationale français.
On s’est intéressé à pouvoir déterminer dans quel état d’esprit se déroule un débat à l'Assemblée nationale.
L’article est organisé en différentes parties une brève explication de la méthodologie. La partie suivante permettra de présenter les résultats obtenus, puis nous évoquerons notre analyse à partir des précédées données et une brève conclusion.


## Démarche d'acquisition des données et construction des données
Pour collecter les données nécessaire à réaliser notre étude, nous sommes allés les récupérer directement depuis le site de l’assemblé national. Les données sont de très bonne qualité car ce sont des professionnels qui réalisent ces transcriptions. Nous avons sélectionné un débat qui c’est déroulée pendant la 123eme séance du 12 février 2017.
Pour ce faire, nous avons dû utiliser la librairie “rvest” sur rstudio qui permet d'importer l’arbre html de la page. Puis dans un second temp, on avait extrait les textes de chaque allocution chronologiquement.
Enfin pour enrichir les données extraites, nous avons discriminer les données en fonction du sexe et du rôle exercé par locution.
Puis dans un second temps nous avons isolé chaque mots via une fonction de R tout en conserve les informations de son énonciateur. 
Pour augmenter la pertinence pendant l’analyse sur la liste de mot, nous avons fait le choix de retirer les mots qui ne sont pas significatif (mots non porteur de sens). Par la suite on a continuer à diviser les tâches entre nous sur l’analyse des sentiments, les bigrams par fréquence et les mots les plus utilisés.

##Question sur laquelle se base l'analyse
**Dans quelle atmosphère se déroulent les débats au sein de l'Assemblée nationale par l'analyse textuelle.**


## Méthodes de travail
Dans une approche de travail en groupe (4 personnes), nous avons décidé d'utiliser différents outils de collaboration et de partage de source. Le principal outil utilisé a été un “Repositories Git” qui permet de gérer les différents travaux en concurrence et garder des versions sur serveur.
Pour débuter, nous avons choisi de faire de la veille sur les différents techniques existant par la lecture de publication scientifique en rapport avec notre problématique. Notre tuteur nous a envoyé de nombreux document qui nous a beaucoup aidé sur la compréhension du sujet et savoir bien ce qui demander à faire. Puis dans un second temps, nous utiliserons l’IDE R-studio pour récupérer nos jeux donnés et réaliser des analyses par le moyen du graphique ou de résultat numérique.

# Analyse Statistique (Text mining)

## Chargement des Packages utilisées
```{r}
#install.packages("syuzhet")
#install.packages("tm")
#install.packages("rvest")
#install.packages("xml2")
#install.packages("stringi")
#install.packages("stringr")
#install.packages("dplyr")
#install.packages("tidytext")
#install.packages("ggplot2")
```


## L’analyse des sentiments
Suite au traitement décrit au préalable dans la partie démarche et acquisition données. À partir des textes extraits, nous réalisons l’analyse des sentiments pour tenter de prévoir les réactions, les attitudes, le contexte et les émotions des députés. On se concentre notamment sur la différence entre les hommes et les femmes. Cette analyse est basé sur un ensemble de mots ‘Lexiques' qu’ils sont divisés en trois parties positifs, négatifs et neutre. Pour cela nous avons utilisé le “package syuzhet”. En revanche, cette analyse s’effectue par l’intersection des mots extraient dans la première partie et les mots du package utiliser.



```{r, include=TRUE}
library(rvest)
library(xml2)
library(stringi)
# Extraction de la page html d'une séance unique (123eme) du 22/02/2017
textTreeBase <- read_html("http://www.assemblee-nationale.fr/14/cri/2016-2017/20170123.asp")

# Extraction 
textSeance20170123<- textTreeBase %>% html_nodes("body") %>% html_nodes("p") %>% html_text() #extraction dans le noeud <body> puis dnas le noeud <p>

```

```{r, include=FALSE}
library(stringr)
library(dplyr)
# Création d'un object Data
text_seance20170123 <- tibble(line = 1:length(textSeance20170123), text = textSeance20170123)

# utilisation des regex pour désigner les hommes et les femmes
sexeM <- c("M\\. ")
sexeF <- c("Mme ")

president <- c("M\\. le président\\.")

#On ne garde que les discour des hommes et femmes dicriminer par leur sexe
text_seance20170123 <- text_seance20170123 %>%
  rowwise() %>% 
  mutate(sexe = if(str_detect(text, sexeM)) "Homme" else if(str_detect(text, sexeF)) "Femme" else "autre") %>% 
  filter(sexe != "autre")

text_seance20170123 <- text_seance20170123 %>%
  rowwise() %>% 
  mutate(rôle = if(str_detect(text,president)) "Président" else "Député")
```


```{r, include=FALSE}
library(tidytext)
library(stringr)
library(dplyr)
library(ggplot2)
t <- text_seance20170123 %>% 
  unnest_tokens(word, text) %>%
  filter(!str_detect(word, "[0-9]"))

t %>%
  count(word, sort = TRUE) %>%
  filter(n > 100) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()

#Filtre les nombres dans les mots et calcule le nombres de mots identique en fonction du sexe
t2 <- t %>%
  count(word,sexe, sort = TRUE)
```


```{r, include=FALSE}
#Les mots exclus
motstop <- read.delim("./stopword/stopwords-fr.txt")

t3 <-t2
t3 <- t3 %>%
  anti_join(motstop)
```
```{r, include=FALSE}
#Les mots exclus
motstop2 <- read.delim("./stopword/stopword2-fr.txt")

t4 <-t2
t4 <- t4 %>%
  anti_join(motstop2)
```


```{r, include=FALSE}
t3 %>%
  group_by(sexe) %>%
  top_n(30) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sexe)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sexe, scales = "free_y") +
  labs(y = "Les Mots les plus utilisé avec filtre 1", x = NULL) +
  coord_flip()

t4 %>%
  group_by(sexe) %>%
  top_n(30) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sexe)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sexe, scales = "free_y") +
  labs(y = "Les Mots les plus utilisé avec filtre 2", x = NULL) +
  coord_flip()
```
On Observe que le premier filtre n'est pas adéquate car il retire bien trop de mot sigificatif comme "politiques"


Donc dans la suite des traitement nous utiliserons que le filtre 2 si besoin.

Pour ces deux graphes, on a analysé les termes utiliser dans les débats sans differencier entre homme et femme.
```{r, include=FALSE}

library(syuzhet)
library(tm)
library(ggplot2)
result <-get_nrc_sentiment(t[["word"]])
result1<-data.frame(t(result))
new_result <- data.frame(rowSums(result1))
names(new_result)[1] <- "count"
new_result <- cbind("sentiment" = rownames(new_result), new_result)
rownames(new_result) <- NULL
qplot(sentiment, data=new_result[1:8,], weight=count, geom="bar",fill=sentiment)+ggtitle("Graphe d'analyse des sentiments de tous les alocutions")
```
Ce graphe nous permet de deduire que il utiliser les mots de confiance le plus souvent apres on voit les termes d'anticipation et de peur.

```{r, include=FALSE}
qplot(sentiment, data=new_result[9:10,], weight=count, geom="bar",fill=sentiment)+ggtitle("Graphe d'analyse de tous les alocutions Positif et Negatif")
```
Ce graphe permet d'illustrer que les termes positifs domine sur les termes negatifs dans les débats.



```{r, include=FALSE}

t$word[t$sexe=="Femme"]->wordofWomen
t$word[t$sexe=="Homme"]->wordofMan

#partie Homme 
library(syuzhet)
library(tm)
library(ggplot2)
resultMan <-get_nrc_sentiment(wordofMan)
resultMan1<-data.frame(t(resultMan))
new_resultMan <- data.frame(rowSums(resultMan1))
names(new_resultMan)[1] <- "count"
new_resultMan <- cbind("sentiment" = rownames(new_resultMan), new_resultMan)
rownames(new_resultMan) <- NULL
qplot(sentiment, data=new_resultMan[1:8,], weight=count, geom="bar",fill=sentiment)+ggtitle("Graphe d'analyse des Sentiments discours Homme ")
qplot(sentiment, data=new_resultMan[9:10,], weight=count, geom="bar",fill=sentiment)+ggtitle("Graphe d'analyse des Sentiments discours Homme ")


#partie Femme 
resultWomen <-get_nrc_sentiment(wordofWomen)
resultWomen1<-data.frame(t(resultWomen))
new_resultWomen <- data.frame(rowSums(resultWomen1))
names(new_resultWomen)[1] <- "count"
new_resultWomen <- cbind("sentiment" = rownames(new_resultWomen), new_resultWomen)
rownames(new_resultMan) <- NULL
qplot(sentiment, data=new_resultWomen[1:8,], weight=count, geom="bar",fill=sentiment)+ggtitle("Graphe d'analyse des Sentiments discours Femme")
qplot(sentiment, data=new_resultWomen[9:10,], weight=count, geom="bar",fill=sentiment)+ggtitle("Graphe d'analyse des Sentiments discours Femme")

```
En comparant le premier graphe entre femme et homme on peut deduire que les hommes parlent plus avec des termes de sentiment d'anticipation et de confiance alors que les femmes parlent de sentiment de peur, tristesse.La on peut deduire que les femmes y a une grande partie dans leur discours des expressions d'?motions plus que les hommes.


```{r, include=FALSE}

t  %>%   
  inner_join(get_sentiments("nrc")) %>%
  group_by(index = line %/% 25, sexe , sentiment) %>%
  summarize(n = n()) %>%
  ggplot(aes(x = index, y = n, fill = sexe )) + 
  geom_bar(stat = "identity", alpha = 0.8) + 
  facet_wrap(~ sentiment, ncol = 5) 

 

```

### Methodologie et Analyse
Il peut etre interessant de montrer les relatations ou des correleations entre les mots pour cela  nous prodedons au calculs bi-grams :
sequence continue de 2 mots

D'abord nous allons sectionner le tableau de mot duc corpus en tokens de 2 
Puis on genere un tableau avec 2 colonnes reprenants les token calcules
Puis on enleve les mots non pertinants
Finallement on trie les bigrams par fequence

```{r, include=FALSE}
library(tidyr)
library(stringr)
library(dplyr)
library(tidytext)
# 2-token unnnesting
textBigram <- t %>%  
  unnest_tokens(ngramData, word, token = "ngrams", n = 2)
#sort and count
textBigram %>% count(ngramData, sort = TRUE)

bigrams_separated <- textBigram %>%
  separate(ngramData, c("ngram1", "ngram2"), sep = " ")



bigrams_filtered <- bigrams_separated %>%
  filter(!ngram1 %in% motstop2$word) %>%
  filter(!ngram2 %in% motstop2$word)

# new bigram counts:
bigram_counts <- bigrams_filtered %>% 
  count(ngram1, ngram2, sort = TRUE)

bigram_counts

```

Resultat :
Les bigrams  comme secretaire d'etat et  groupe socialiste apparaissent le plus soucant dans ce corpus ce qui surligne leur importance dans le debat.
